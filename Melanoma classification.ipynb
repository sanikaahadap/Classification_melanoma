{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff5e96f7-c306-4895-950b-9f60a3e0262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 images belonging to 2 classes.\n",
      "Found 30 images belonging to 2 classes.\n",
      "Found 30 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths to your dataset directories\n",
    "train_dir = 'train'\n",
    "validation_dir = 'valid'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Load COCO JSON files\n",
    "def load_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)['annotations']\n",
    "    return data\n",
    "\n",
    "train_annotations = load_annotations('train/_annotations.coco.json')\n",
    "valid_annotations = load_annotations('valid/_annotations.coco.json')\n",
    "test_annotations = load_annotations('test/_annotations.coco.json')\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06964ba4-cb5e-4ffe-9c59-372622c4ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SANIKA\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SANIKA\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 7s 0us/step\n",
      "WARNING:tensorflow:From C:\\Users\\SANIKA\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\SANIKA\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SANIKA\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.9420 - accuracy: 0.4784 - val_loss: 0.7628 - val_accuracy: 0.4667\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.6547 - accuracy: 0.5957 - val_loss: 0.7669 - val_accuracy: 0.5333\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.5514 - accuracy: 0.6821 - val_loss: 0.4824 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 41s 4s/step - loss: 0.3876 - accuracy: 0.8519 - val_loss: 0.4393 - val_accuracy: 0.7333\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.3123 - accuracy: 0.8889 - val_loss: 0.4149 - val_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 42s 4s/step - loss: 0.2662 - accuracy: 0.9198 - val_loss: 0.4012 - val_accuracy: 0.7667\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.2250 - accuracy: 0.9475 - val_loss: 0.3845 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.2221 - accuracy: 0.9105 - val_loss: 0.3617 - val_accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.1923 - accuracy: 0.9383 - val_loss: 0.3574 - val_accuracy: 0.8333\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 46s 4s/step - loss: 0.1774 - accuracy: 0.9414 - val_loss: 0.3672 - val_accuracy: 0.8667\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - accuracy: 0.9667\n",
      "Test accuracy: 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the VGG16 model pretrained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the convolutional base\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # Adjust output classes as per your dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cc7ef2c-c829-4e2a-8319-2524fe04b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model_VGG16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model_VGG16\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Model_VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68434226-eaf7-4fe3-8873-278b8f6f191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step\n",
      "Predicted Class Index: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('C:/Users/SANIKA/Desktop/Research Intern/Melanoma_classification.v1i.coco/Model_VGG16')\n",
    "\n",
    "# Define a function to preprocess the image and predict the class\n",
    "def predict_image_class(image_path, model):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0  # Normalize pixel values\n",
    "    pred = model.predict(x)\n",
    "    class_index = np.argmax(pred)\n",
    "    return class_index\n",
    "\n",
    "# Example usage to predict an external image\n",
    "image_path = 'xyz.jpg'  # Replace with the path to your image\n",
    "predicted_class_index = predict_image_class(image_path, model)\n",
    "\n",
    "# Print the predicted class index\n",
    "print(\"Predicted Class Index:\", predicted_class_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
